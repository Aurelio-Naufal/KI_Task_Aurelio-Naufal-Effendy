{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk9QT9Ma7W7mA10t8AR8EI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aurelio-Naufal/KI_Task_Aurelio-Naufal-Effendy/blob/main/TaskWeek7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Aurelio Naufal Effendy\n",
        "\n",
        "NPM : 2106638526\n",
        "\n",
        "Kelas : Komputasi Intelegensia"
      ],
      "metadata": {
        "id": "hu65goKMxiLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VImsfG7uYqLm"
      },
      "outputs": [],
      "source": [
        "!pip install indonlp -q\n",
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentimen Analysis Model Using bert-base-indonesian-1.5G-sentiment-analysis-smsa model"
      ],
      "metadata": {
        "id": "euSQ2YCZaalL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned BERT model for Indonesian sentiment analysis\n",
        "sentiment_analysis = pipeline(\"text-classification\", model=\"ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\")\n",
        "\n",
        "# Test the model on an example sentence\n",
        "result = sentiment_analysis(\"Film ini sangat bagus, saya menyukainya!\")\n",
        "print(f\"Sentiment: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weK7Io3xZtF5",
        "outputId": "a3e11de9-7ae7-40dc-dbb0-0116e7e7c9db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: [{'label': 'Positive', 'score': 0.999775230884552}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on another sentences\n",
        "result = sentiment_analysis(\"Film ini sangat membosankan\")\n",
        "print(f\"Sentiment: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArSNeLF0bT8W",
        "outputId": "81a64698-608f-4451-d9aa-bd7ffec3fcad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: [{'label': 'Negative', 'score': 0.9998849630355835}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check model's accuracy using a synthetic dataset"
      ],
      "metadata": {
        "id": "c2G8oX4_cqGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the Indonesian Sentiment dataset\n",
        "dataset = load_dataset(\"sepidmnorozy/Indonesian_sentiment\")\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "num_data_points = len(test_data)\n",
        "print(f\"Number of data points in the train dataset: {num_data_points}\")\n",
        "\n",
        "# Print an example\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCY3h8mmcc8M",
        "outputId": "92d48330-8829-4536-937d-05a0dcf8c2ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points in the train dataset: 2266\n",
            "{'label': 1, 'text': 'bubur ayam yang lumayan rekomendasi di sekitaran bandung , tempat nya strategis mudah dicari , harga nya tidak merogoh kantong , tempat nya selalu ramai didatangi pengunjung setiap hari kerja maupun akhir pekan karena rasanya yang enak .'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_data[:500] #use 500 data only"
      ],
      "metadata": {
        "id": "OLMdAaxisqEf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiments(texts):\n",
        "    # Tokenize and make predictions for each text\n",
        "    predictions = []\n",
        "    for text in tqdm(texts):\n",
        "        sentiment = sentiment_analysis(text)\n",
        "        predictions.append(sentiment)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "XI5i3XeHk2qg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Model's accuracy"
      ],
      "metadata": {
        "id": "iqDBG-Kk03Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    0: 'Negative',\n",
        "    1: 'Positive',\n",
        "}"
      ],
      "metadata": {
        "id": "0pw1Q1JFlULJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [label_mapping[label] for label in test_dataset['label']]"
      ],
      "metadata": {
        "id": "HDbREk6xnQKV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test split of the Indonesian Sentiment dataset\n",
        "predicted_labels = predict_sentiments(test_dataset['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag9JMw-blAEe",
        "outputId": "cc03a325-3e19-4423-9b1f-2a7fcf8c5ece"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:50<00:00,  4.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_labels = [pred[0]['label'] for pred in predicted_labels]"
      ],
      "metadata": {
        "id": "VFvYeCuEnYPB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "accuracy = sum(np.array(extracted_labels) == np.array(true_labels)) / len(true_labels)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iginfngUlR0C",
        "outputId": "2cf49aaf-21c1-475a-f7e5-4d2c9d61fee0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy is pretty good, reaching 99.2%"
      ],
      "metadata": {
        "id": "9KUXTkaZn-mY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Attention Transformer"
      ],
      "metadata": {
        "id": "9YGoJWZgoSLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = \"ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "class CustomBERTWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=768, num_heads=8)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(768, 2)  # 2 classes: positive and negative\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # Use the mean of hidden states as input to the attention layer\n",
        "        attn_output, _ = self.attention(hidden_states, hidden_states, hidden_states)\n",
        "        pooled_output = torch.mean(attn_output, dim=1)  # Aggregate the attention output\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Initialize the custom model\n",
        "custom_model = CustomBERTWithAttention()\n",
        "\n",
        "# Move the model to the appropriate device (CPU/GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8x0evvmoIuR",
        "outputId": "17bccb00-6564-4acd-cfd6-d226bfe26ae7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBERTWithAttention(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict sentiments using the custom model\n",
        "def predict_sentiments(texts):\n",
        "    # Tokenize inputs\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = custom_model(inputs['input_ids'], inputs['attention_mask'])\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    # Get predicted class labels\n",
        "    predicted_labels = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "WvdXWw9goMHv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Model's accuracy with attention mask"
      ],
      "metadata": {
        "id": "ecl_Fp8o07-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted labels using the defined function\n",
        "predicted_labels_with_attention = predict_sentiments(test_dataset['text'])\n",
        "predicted_labels_with_attention"
      ],
      "metadata": {
        "id": "MV-Mo11Yoxuv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_labels_with_attention = [label_mapping[label] for label in predicted_labels_with_attention]"
      ],
      "metadata": {
        "id": "x1NOO-YMwQHt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy_with_attention = sum(np.array(extracted_labels_with_attention) == np.array(true_labels)) / len(true_labels)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgGrXUcdsKAj",
        "outputId": "6925bcad-4bca-4b62-cba1-1d03bcf1ff54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It got the exact same accuracy"
      ],
      "metadata": {
        "id": "2qHAxuc_xeNT"
      }
    }
  ]
}